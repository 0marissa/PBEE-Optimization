{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d76c2914",
   "metadata": {},
   "source": [
    "## Neural network training notebook\n",
    "### Hazard level: 475 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5d8568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, explained_variance_score,r2_score\n",
    "import pickle\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "\n",
    "#%% Read and manipulate data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "737654c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Settings\n",
    "pTrain = 0.8\n",
    "pValidate = 0.1\n",
    "pTest = 0.1\n",
    "\n",
    "#Load data from file\n",
    "df_random = pd.read_csv('475_rand_imp1.csv')\n",
    "df_edge = pd.read_csv('475_edge_imp1.csv')\n",
    "\n",
    "flag = 2 # 1 trained on all data, 2 on random data, and 3 on edge cases\n",
    "\n",
    "if flag == 1:\n",
    "        data = np.concatenate((df_random.to_numpy(),df_edge.to_numpy()))\n",
    "if flag == 2:\n",
    "        data = df_random.to_numpy()\n",
    "        \n",
    "# Definition of inputs and outputs\n",
    "np.random.shuffle(data)\n",
    "\n",
    "size_data = data.shape\n",
    "\n",
    "input_data = data[:,:(size_data[1]-1)]\n",
    "output_data = data[:,-1]\n",
    "\n",
    "edge_data = df_edge.to_numpy()\n",
    "edge_data_input = edge_data[:,:(size_data[1]-1)]\n",
    "edge_data_label = edge_data[:,-1]\n",
    "\n",
    "non_edge_data = df_random.to_numpy()\n",
    "non_edge_data_input = non_edge_data[:,:(size_data[1]-1)]\n",
    "non_edge_data_label = non_edge_data[:,-1]\n",
    "\n",
    "# Normal standarization of data \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b013834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the \"transform\" (mus, sigmas) in a pickle, to be applied to the data later\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "\n",
    "input_data = scaler.transform(input_data)\n",
    "edge_data_input = scaler.transform(edge_data_input)\n",
    "non_edge_data_input = scaler.transform(non_edge_data_input)\n",
    "\n",
    "# Split into training, validation and testing set\n",
    "# p1 and p2 are thresholds to which the data is divided\n",
    "# DATA MUST BE SHUFFLED\n",
    "p1 = int(size_data[0]*pTrain) # train\n",
    "train_data = input_data[:p1,:]\n",
    "train_label = output_data[:p1]\n",
    "\n",
    "p2 = int(size_data[0]*(pTrain+pValidate)) # validate and test\n",
    "valid_data = input_data[p1:p2,:]\n",
    "valid_label = output_data[p1:p2]\n",
    "test_data = input_data[p2:,:]\n",
    "test_label = output_data[p2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd102e1d",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79a4ee54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Fitted\n"
     ]
    }
   ],
   "source": [
    "# Training model. We're using scikit-learn since it works well with Numpy\n",
    "# Hyperparameters that we found are entered.\n",
    "mlp = MLPRegressor(hidden_layer_sizes=20*(150,), learning_rate_init=0.0003, alpha=0.0001)\n",
    "mlp.fit(train_data, train_label)\n",
    "print('Model Fitted')\n",
    "\n",
    "#Saving model for posteriority\n",
    "#\n",
    "with open('model_fitted_all_475_imp1.pkl', 'wb') as f:\n",
    "        pickle.dump(mlp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "710cd688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train data\n",
      "0.9991080242658484\n",
      "R2 test data\n",
      "0.9980699731801911\n",
      "R2 edge data\n",
      "0.8457787500025927\n",
      "R2 non-edge data\n",
      "0.9989229828410735\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Load saved model so we don't need to train everytime\n",
    "\n",
    "mlp = pickle.load(open('model_fitted_all_475_imp1.pkl','rb'))\n",
    "\n",
    "# Computing values predicted by the neural network\n",
    "\n",
    "nn_train_label = mlp.predict(train_data)\n",
    "nn_test_label = mlp.predict(test_data)\n",
    "\n",
    "nn_edge_label = mlp.predict(edge_data_input)\n",
    "nn_non_edge_label = mlp.predict(non_edge_data_input)\n",
    "\n",
    "\n",
    "#Computing R2 error\n",
    "r2_train = r2_score(train_label,nn_train_label)\n",
    "r2_test = r2_score(test_label,nn_test_label)\n",
    "r2_edge = r2_score(edge_data_label,nn_edge_label)\n",
    "r2_non_edge = r2_score(non_edge_data_label,nn_non_edge_label)\n",
    "#plotting scatter plot of NN vs Label\n",
    "\n",
    "\n",
    "#Printing accuracy values\n",
    "print('R2 train data')\n",
    "print(r2_train)\n",
    "print('R2 test data')\n",
    "print(r2_test)\n",
    "\n",
    "print('R2 edge data')\n",
    "print(r2_edge)\n",
    "\n",
    "print('R2 non-edge data')\n",
    "print(r2_non_edge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899a6e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(test_label,nn_test_label,s=4)\n",
    "plt.plot([0,40],[0,40],color = 'orange')\n",
    "plt.xlabel('Test data')\n",
    "plt.ylabel('NN prediction')\n",
    "plt.title('NN prediction versus test set: 475-year RP with impeding factors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c36259de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(output_data, bins=40)\n",
    "plt.title('Histogram: $T_{FR,50}$ training data')\n",
    "plt.grid(alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebebbaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Perform sensitivity analysis'''\n",
    "n_component = 41\n",
    "n_increases = 21\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "sens_matrix = np.zeros((n_component,n_increases))\n",
    "\n",
    "''' Example discussed while teaching how to use the code'''\n",
    "\n",
    "input_to_evaluate = np.ones((1,41))\n",
    "input_to_evaluate[4] = 2.5\n",
    "input_to_evaluate = scaler.transform(input_to_evaluate)\n",
    "output_value = mlp.predict(input_to_evaluate)\n",
    "\n",
    "for i in range(n_component):\n",
    "        for j in range(n_increases):\n",
    "                vector_input = np.ones((1,n_component))\n",
    "                vector_input[0][i] = 1 + j*0.1\n",
    "                vector_input = scaler.transform(vector_input)\n",
    "                pred_val = mlp.predict(vector_input)\n",
    "                sens_matrix[i][j] = pred_val[0]\n",
    "t1 = time.time()\n",
    "\n",
    "print(t1-t0)\n",
    "\n",
    "with open('sensitivity_matrix.pkl','wb') as f:\n",
    "        pickle.dump(sens_matrix,f)\n",
    "\n",
    "np.savetxt('sensitivity_matrix.csv',sens_matrix,delimiter=',')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
